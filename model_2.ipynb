{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc0bcf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import xgboost as xgb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "class SugarcanePredictionPipeline:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.results = {}\n",
    "        self.models = {}\n",
    "        self.scalers = {}\n",
    "        self.stage_results = {}\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and prepare the sugarcane dataset\"\"\"\n",
    "        data_dict = {\n",
    "            'Year': [2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022],\n",
    "            'Land_use': [380.543, 391.291, 389.417, 308.104, 338.626, 329.303, 375.216, 376.530, 447.204, 453.470, 442.958, 395.399, 368.426, 363.220, 336.003],\n",
    "            'Yield': [85.72, 80.39, 80.2, 81.73, 76.65, 82.40, 81.33, 85.99, 76.93, 80.63, 75.64, 81.98, 82.65, 85.93, 85.32],\n",
    "            'Sugar_Production': [4939000, 4814000, 4700000, 3700000, 3683000, 4250000, 4380000, 4700000, 4900000, 5100000, 4480000, 4725000, 4285000, 4335000, 4120000],\n",
    "            'Exported_Sugar': [3700000, 3552000, 3600000, 2750000, 2800000, 3100000, 3242000, 3561000, 3700000, 4000000, 3600000, 3735000, 3600000, 3400000, 3120000]\n",
    "        }\n",
    "        self.data = pd.DataFrame(data_dict)\n",
    "        print(\"Dataset loaded successfully!\")\n",
    "        print(f\"Shape: {self.data.shape}\")\n",
    "        print(self.data.head())\n",
    "        \n",
    "    def visualize_data(self):\n",
    "        \"\"\"Create comprehensive visualizations\"\"\"\n",
    "        fig = plt.figure(figsize=(20, 15))\n",
    "        \n",
    "        # 1. Overview of all variables\n",
    "        plt.subplot(3, 3, 1)\n",
    "        plt.plot(self.data['Year'], self.data['Land_use'], 'o-', label='Land Use', linewidth=2, markersize=6)\n",
    "        plt.plot(self.data['Year'], self.data['Yield'], 'o-', label='Yield', linewidth=2, markersize=6)\n",
    "        plt.title('Land Use and Yield Over Time', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Value')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. Production and Export\n",
    "        plt.subplot(3, 3, 2)\n",
    "        plt.plot(self.data['Year'], self.data['Sugar_Production']/1000, 'o-', label='Production (k tonnes)', linewidth=2, markersize=6)\n",
    "        plt.plot(self.data['Year'], self.data['Exported_Sugar']/1000, 'o-', label='Export (k tonnes)', linewidth=2, markersize=6)\n",
    "        plt.title('Sugar Production and Export', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Thousand Tonnes')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. Correlation matrix\n",
    "        plt.subplot(3, 3, 3)\n",
    "        corr_matrix = self.data[['Land_use', 'Yield', 'Sugar_Production', 'Exported_Sugar']].corr()\n",
    "        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, square=True, fmt='.2f')\n",
    "        plt.title('Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # 4. Distribution plots\n",
    "        plt.subplot(3, 3, 4)\n",
    "        plt.hist(self.data['Land_use'], bins=8, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        plt.title('Land Use Distribution', fontsize=12, fontweight='bold')\n",
    "        plt.xlabel('Land Use (1000 ha)')\n",
    "        \n",
    "        plt.subplot(3, 3, 5)\n",
    "        plt.hist(self.data['Yield'], bins=8, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "        plt.title('Yield Distribution', fontsize=12, fontweight='bold')\n",
    "        plt.xlabel('Yield (t/ha)')\n",
    "        \n",
    "        # 5. Scatter plots\n",
    "        plt.subplot(3, 3, 6)\n",
    "        plt.scatter(self.data['Land_use'], self.data['Sugar_Production'], alpha=0.7, s=60, color='orange')\n",
    "        plt.title('Land Use vs Production', fontsize=12, fontweight='bold')\n",
    "        plt.xlabel('Land Use (1000 ha)')\n",
    "        plt.ylabel('Sugar Production')\n",
    "        \n",
    "        plt.subplot(3, 3, 7)\n",
    "        plt.scatter(self.data['Yield'], self.data['Sugar_Production'], alpha=0.7, s=60, color='red')\n",
    "        plt.title('Yield vs Production', fontsize=12, fontweight='bold')\n",
    "        plt.xlabel('Yield (t/ha)')\n",
    "        plt.ylabel('Sugar Production')\n",
    "        \n",
    "        # 6. Normalized trends\n",
    "        plt.subplot(3, 3, 8)\n",
    "        for col in ['Land_use', 'Yield', 'Sugar_Production', 'Exported_Sugar']:\n",
    "            normalized = (self.data[col] - self.data[col].min()) / (self.data[col].max() - self.data[col].min())\n",
    "            plt.plot(self.data['Year'], normalized, 'o-', label=col, linewidth=2, markersize=4)\n",
    "        plt.title('Normalized Trends', fontsize=12, fontweight='bold')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Normalized Value (0-1)')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 7. Statistical summary\n",
    "        plt.subplot(3, 3, 9)\n",
    "        plt.axis('off')\n",
    "        stats_text = self.data.describe().round(2).to_string()\n",
    "        plt.text(0.1, 0.9, \"Statistical Summary:\", fontsize=12, fontweight='bold', transform=plt.gca().transAxes)\n",
    "        plt.text(0.1, 0.1, stats_text, fontsize=8, fontfamily='monospace', transform=plt.gca().transAxes)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def create_time_series_features(self, target_col, window_size=3):\n",
    "        \"\"\"Create sliding window features for time series prediction\"\"\"\n",
    "        X, y = [], []\n",
    "        target_values = self.data[target_col].values\n",
    "        \n",
    "        for i in range(window_size, len(target_values)):\n",
    "            X.append(target_values[i-window_size:i])\n",
    "            y.append(target_values[i])\n",
    "        \n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    def evaluate_model(self, y_true, y_pred, model_name=\"Model\"):\n",
    "        \"\"\"Calculate evaluation metrics\"\"\"\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        \n",
    "        return {\n",
    "            'Model': model_name,\n",
    "            'R2': r2,\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae\n",
    "        }\n",
    "    \n",
    "    def stage_0_predict_land_use(self):\n",
    "        \"\"\"Stage 0: Predict Land Use using time series models\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ðŸŸ© STAGE 0: PREDICTING LAND USE\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        X, y = self.create_time_series_features('Land_use', window_size=3)\n",
    "        \n",
    "        # Split data for time series (use last 20% for testing)\n",
    "        split_idx = int(0.8 * len(X))\n",
    "        X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "        y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "        \n",
    "        models_results = []\n",
    "        \n",
    "        # 1. ARIMA Model\n",
    "        print(\"Training ARIMA model...\")\n",
    "        try:\n",
    "            arima_model = ARIMA(self.data['Land_use'].values, order=(1,1,1))\n",
    "            arima_fitted = arima_model.fit()\n",
    "            arima_pred = arima_fitted.forecast(steps=len(y_test))\n",
    "            arima_results = self.evaluate_model(y_test, arima_pred, \"ARIMA\")\n",
    "            models_results.append(arima_results)\n",
    "        except:\n",
    "            print(\"ARIMA failed, using simple moving average\")\n",
    "            arima_pred = np.mean(y_train) * np.ones(len(y_test))\n",
    "            arima_results = self.evaluate_model(y_test, arima_pred, \"ARIMA\")\n",
    "            models_results.append(arima_results)\n",
    "        \n",
    "        # 2. Random Forest with lag features\n",
    "        print(\"Training Random Forest...\")\n",
    "        rf_params = {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [3, 5, 7, None],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "        rf = RandomForestRegressor(random_state=42)\n",
    "        rf_grid = GridSearchCV(rf, rf_params, cv=3, scoring='r2', n_jobs=-1)\n",
    "        rf_grid.fit(X_train, y_train)\n",
    "        rf_pred = rf_grid.predict(X_test)\n",
    "        rf_results = self.evaluate_model(y_test, rf_pred, \"Random Forest\")\n",
    "        models_results.append(rf_results)\n",
    "        \n",
    "        # 3. XGBoost\n",
    "        print(\"Training XGBoost...\")\n",
    "        xgb_params = {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'learning_rate': [0.01, 0.1, 0.2]\n",
    "        }\n",
    "        xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "        xgb_grid = GridSearchCV(xgb_model, xgb_params, cv=3, scoring='r2', n_jobs=-1)\n",
    "        xgb_grid.fit(X_train, y_train)\n",
    "        xgb_pred = xgb_grid.predict(X_test)\n",
    "        xgb_results = self.evaluate_model(y_test, xgb_pred, \"XGBoost\")\n",
    "        models_results.append(xgb_results)\n",
    "        \n",
    "        # 4. LSTM\n",
    "        print(\"Training LSTM...\")\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        lstm_model = Sequential([\n",
    "            LSTM(50, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "            Dropout(0.2),\n",
    "            Dense(25),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        lstm_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "        \n",
    "        X_train_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
    "        X_test_lstm = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
    "        \n",
    "        lstm_model.fit(X_train_lstm, y_train, epochs=100, batch_size=16, verbose=0)\n",
    "        lstm_pred = lstm_model.predict(X_test_lstm, verbose=0).flatten()\n",
    "        lstm_results = self.evaluate_model(y_test, lstm_pred, \"LSTM\")\n",
    "        models_results.append(lstm_results)\n",
    "        \n",
    "        # 5. GRU\n",
    "        print(\"Training GRU...\")\n",
    "        gru_model = Sequential([\n",
    "            GRU(50, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "            Dropout(0.2),\n",
    "            Dense(25),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        gru_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "        gru_model.fit(X_train_lstm, y_train, epochs=100, batch_size=16, verbose=0)\n",
    "        gru_pred = gru_model.predict(X_test_lstm, verbose=0).flatten()\n",
    "        gru_results = self.evaluate_model(y_test, gru_pred, \"GRU\")\n",
    "        models_results.append(gru_results)\n",
    "        \n",
    "        # 6. Ensemble (Average)\n",
    "        print(\"Creating Ensemble...\")\n",
    "        ensemble_pred = np.mean([arima_pred, rf_pred, xgb_pred, lstm_pred, gru_pred], axis=0)\n",
    "        ensemble_results = self.evaluate_model(y_test, ensemble_pred, \"Ensemble\")\n",
    "        models_results.append(ensemble_results)\n",
    "        \n",
    "        # Display results\n",
    "        results_df = pd.DataFrame(models_results)\n",
    "        print(\"\\nStage 0 Results:\")\n",
    "        print(results_df.to_string(index=False))\n",
    "        \n",
    "        # Store best model predictions for next stage\n",
    "        best_model_idx = results_df['R2'].idxmax()\n",
    "        best_model_name = results_df.loc[best_model_idx, 'Model']\n",
    "        print(f\"\\nBest Model: {best_model_name} (RÂ² = {results_df.loc[best_model_idx, 'R2']:.4f})\")\n",
    "        \n",
    "        self.stage_results['Stage_0'] = {\n",
    "            'results': results_df,\n",
    "            'predictions': ensemble_pred,  # Use ensemble for next stage\n",
    "            'y_test': y_test,\n",
    "            'best_model': best_model_name\n",
    "        }\n",
    "        \n",
    "        return results_df\n",
    "    \n",
    "    def stage_1_predict_yield(self):\n",
    "        \"\"\"Stage 1: Predict Sugarcane Yield from Land Use\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ðŸŸ¨ STAGE 1: PREDICTING SUGARCANE YIELD\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        X = self.data[['Land_use']].values\n",
    "        y = self.data['Yield'].values\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        \n",
    "        models_results = []\n",
    "        \n",
    "        # 1. Linear Regression\n",
    "        print(\"Training Linear Regression...\")\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(X_train, y_train)\n",
    "        lr_pred = lr.predict(X_test)\n",
    "        lr_results = self.evaluate_model(y_test, lr_pred, \"Linear Regression\")\n",
    "        models_results.append(lr_results)\n",
    "        \n",
    "        # 2. SVM\n",
    "        print(\"Training SVM...\")\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        svm_params = {\n",
    "            'C': [0.1, 1, 10, 100],\n",
    "            'gamma': ['scale', 'auto'],\n",
    "            'kernel': ['rbf', 'linear']\n",
    "        }\n",
    "        svm = SVR()\n",
    "        svm_grid = GridSearchCV(svm, svm_params, cv=3, scoring='r2')\n",
    "        svm_grid.fit(X_train_scaled, y_train)\n",
    "        svm_pred = svm_grid.predict(X_test_scaled)\n",
    "        svm_results = self.evaluate_model(y_test, svm_pred, \"SVM\")\n",
    "        models_results.append(svm_results)\n",
    "        \n",
    "        # 3. Random Forest\n",
    "        print(\"Training Random Forest...\")\n",
    "        rf_params = {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [3, 5, 7, None],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "        rf = RandomForestRegressor(random_state=42)\n",
    "        rf_grid = GridSearchCV(rf, rf_params, cv=3, scoring='r2')\n",
    "        rf_grid.fit(X_train, y_train)\n",
    "        rf_pred = rf_grid.predict(X_test)\n",
    "        rf_results = self.evaluate_model(y_test, rf_pred, \"Random Forest\")\n",
    "        models_results.append(rf_results)\n",
    "        \n",
    "        # 4. XGBoost\n",
    "        print(\"Training XGBoost...\")\n",
    "        xgb_params = {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'learning_rate': [0.01, 0.1, 0.2]\n",
    "        }\n",
    "        xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "        xgb_grid = GridSearchCV(xgb_model, xgb_params, cv=3, scoring='r2')\n",
    "        xgb_grid.fit(X_train, y_train)\n",
    "        xgb_pred = xgb_grid.predict(X_test)\n",
    "        xgb_results = self.evaluate_model(y_test, xgb_pred, \"XGBoost\")\n",
    "        models_results.append(xgb_results)\n",
    "        \n",
    "        # 5. LSTM (simplified for single feature)\n",
    "        print(\"Training LSTM...\")\n",
    "        scaler_lstm = MinMaxScaler()\n",
    "        X_train_lstm_scaled = scaler_lstm.fit_transform(X_train)\n",
    "        X_test_lstm_scaled = scaler_lstm.transform(X_test)\n",
    "        \n",
    "        lstm_model = Sequential([\n",
    "            Dense(50, activation='relu', input_shape=(1,)),\n",
    "            Dropout(0.2),\n",
    "            Dense(25, activation='relu'),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        lstm_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "        lstm_model.fit(X_train_lstm_scaled, y_train, epochs=100, batch_size=8, verbose=0)\n",
    "        lstm_pred = lstm_model.predict(X_test_lstm_scaled, verbose=0).flatten()\n",
    "        lstm_results = self.evaluate_model(y_test, lstm_pred, \"LSTM\")\n",
    "        models_results.append(lstm_results)\n",
    "        \n",
    "        # 6. GRU (simplified)\n",
    "        print(\"Training GRU...\")\n",
    "        gru_model = Sequential([\n",
    "            Dense(50, activation='relu', input_shape=(1,)),\n",
    "            Dropout(0.2),\n",
    "            Dense(25, activation='relu'),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        gru_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "        gru_model.fit(X_train_lstm_scaled, y_train, epochs=100, batch_size=8, verbose=0)\n",
    "        gru_pred = gru_model.predict(X_test_lstm_scaled, verbose=0).flatten()\n",
    "        gru_results = self.evaluate_model(y_test, gru_pred, \"GRU\")\n",
    "        models_results.append(gru_results)\n",
    "        \n",
    "        # 7. Ensemble\n",
    "        print(\"Creating Ensemble...\")\n",
    "        ensemble_pred = np.mean([lr_pred, svm_pred, rf_pred, xgb_pred, lstm_pred, gru_pred], axis=0)\n",
    "        ensemble_results = self.evaluate_model(y_test, ensemble_pred, \"Ensemble\")\n",
    "        models_results.append(ensemble_results)\n",
    "        \n",
    "        # Display results\n",
    "        results_df = pd.DataFrame(models_results)\n",
    "        print(\"\\nStage 1 Results:\")\n",
    "        print(results_df.to_string(index=False))\n",
    "        \n",
    "        best_model_idx = results_df['R2'].idxmax()\n",
    "        best_model_name = results_df.loc[best_model_idx, 'Model']\n",
    "        print(f\"\\nBest Model: {best_model_name} (RÂ² = {results_df.loc[best_model_idx, 'R2']:.4f})\")\n",
    "        \n",
    "        self.stage_results['Stage_1'] = {\n",
    "            'results': results_df,\n",
    "            'predictions': ensemble_pred,\n",
    "            'y_test': y_test,\n",
    "            'best_model': best_model_name\n",
    "        }\n",
    "        \n",
    "        return results_df\n",
    "    \n",
    "    def stage_2_predict_production(self):\n",
    "        \"\"\"Stage 2: Predict Sugar Production from Land Use + Yield\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ðŸŸ§ STAGE 2: PREDICTING SUGAR PRODUCTION\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        X = self.data[['Land_use', 'Yield']].values\n",
    "        y = self.data['Sugar_Production'].values\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        \n",
    "        models_results = []\n",
    "        \n",
    "        # 1. Linear Regression\n",
    "        print(\"Training Linear Regression...\")\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(X_train, y_train)\n",
    "        lr_pred = lr.predict(X_test)\n",
    "        lr_results = self.evaluate_model(y_test, lr_pred, \"Linear Regression\")\n",
    "        models_results.append(lr_results)\n",
    "        \n",
    "        # 2. SVM\n",
    "        print(\"Training SVM...\")\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        svm_params = {\n",
    "            'C': [0.1, 1, 10, 100],\n",
    "            'gamma': ['scale', 'auto'],\n",
    "            'kernel': ['rbf', 'linear']\n",
    "        }\n",
    "        svm = SVR()\n",
    "        svm_grid = GridSearchCV(svm, svm_params, cv=3, scoring='r2')\n",
    "        svm_grid.fit(X_train_scaled, y_train)\n",
    "        svm_pred = svm_grid.predict(X_test_scaled)\n",
    "        svm_results = self.evaluate_model(y_test, svm_pred, \"SVM\")\n",
    "        models_results.append(svm_results)\n",
    "        \n",
    "        # 3. Random Forest\n",
    "        print(\"Training Random Forest...\")\n",
    "        rf_params = {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [3, 5, 7, None],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "        rf = RandomForestRegressor(random_state=42)\n",
    "        rf_grid = GridSearchCV(rf, rf_params, cv=3, scoring='r2')\n",
    "        rf_grid.fit(X_train, y_train)\n",
    "        rf_pred = rf_grid.predict(X_test)\n",
    "        rf_results = self.evaluate_model(y_test, rf_pred, \"Random Forest\")\n",
    "        models_results.append(rf_results)\n",
    "        \n",
    "        # 4. XGBoost\n",
    "        print(\"Training XGBoost...\")\n",
    "        xgb_params = {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'learning_rate': [0.01, 0.1, 0.2]\n",
    "        }\n",
    "        xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "        xgb_grid = GridSearchCV(xgb_model, xgb_params, cv=3, scoring='r2')\n",
    "        xgb_grid.fit(X_train, y_train)\n",
    "        xgb_pred = xgb_grid.predict(X_test)\n",
    "        xgb_results = self.evaluate_model(y_test, xgb_pred, \"XGBoost\")\n",
    "        models_results.append(xgb_results)\n",
    "        \n",
    "        # 5. Neural Network (LSTM-style)\n",
    "        print(\"Training Neural Network...\")\n",
    "        scaler_nn = MinMaxScaler()\n",
    "        X_train_nn_scaled = scaler_nn.fit_transform(X_train)\n",
    "        X_test_nn_scaled = scaler_nn.transform(X_test)\n",
    "        \n",
    "        nn_model = Sequential([\n",
    "            Dense(100, activation='relu', input_shape=(2,)),\n",
    "            Dropout(0.3),\n",
    "            Dense(50, activation='relu'),\n",
    "            Dropout(0.2),\n",
    "            Dense(25, activation='relu'),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        nn_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "        nn_model.fit(X_train_nn_scaled, y_train, epochs=150, batch_size=8, verbose=0)\n",
    "        nn_pred = nn_model.predict(X_test_nn_scaled, verbose=0).flatten()\n",
    "        nn_results = self.evaluate_model(y_test, nn_pred, \"Neural Network\")\n",
    "        models_results.append(nn_results)\n",
    "        \n",
    "        # 6. Ensemble\n",
    "        print(\"Creating Ensemble...\")\n",
    "        ensemble_pred = np.mean([lr_pred, svm_pred, rf_pred, xgb_pred, nn_pred], axis=0)\n",
    "        ensemble_results = self.evaluate_model(y_test, ensemble_pred, \"Ensemble\")\n",
    "        models_results.append(ensemble_results)\n",
    "        \n",
    "        # Display results\n",
    "        results_df = pd.DataFrame(models_results)\n",
    "        print(\"\\nStage 2 Results:\")\n",
    "        print(results_df.to_string(index=False))\n",
    "        \n",
    "        best_model_idx = results_df['R2'].idxmax()\n",
    "        best_model_name = results_df.loc[best_model_idx, 'Model']\n",
    "        print(f\"\\nBest Model: {best_model_name} (RÂ² = {results_df.loc[best_model_idx, 'R2']:.4f})\")\n",
    "        \n",
    "        self.stage_results['Stage_2'] = {\n",
    "            'results': results_df,\n",
    "            'predictions': ensemble_pred,\n",
    "            'y_test': y_test,\n",
    "            'best_model': best_model_name\n",
    "        }\n",
    "        \n",
    "        return results_df\n",
    "    \n",
    "    def stage_3_predict_export(self):\n",
    "        \"\"\"Stage 3: Predict Export from Land Use + Yield + Production\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ðŸŸ¥ STAGE 3: PREDICTING SUGAR EXPORT\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        X = self.data[['Land_use', 'Yield', 'Sugar_Production']].values\n",
    "        y = self.data['Exported_Sugar'].values\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        \n",
    "        models_results = []\n",
    "        \n",
    "        # 1. Linear Regression\n",
    "        print(\"Training Linear Regression...\")\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(X_train, y_train)\n",
    "        lr_pred = lr.predict(X_test)\n",
    "        lr_results = self.evaluate_model(y_test, lr_pred, \"Linear Regression\")\n",
    "        models_results.append(lr_results)\n",
    "        \n",
    "        # 2. SVM\n",
    "        print(\"Training SVM...\")\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        svm_params = {\n",
    "            'C': [0.1, 1, 10, 100],\n",
    "            'gamma': ['scale', 'auto'],\n",
    "            'kernel': ['rbf', 'linear']\n",
    "        }\n",
    "        svm = SVR()\n",
    "        svm_grid = GridSearchCV(svm, svm_params, cv=3, scoring='r2')\n",
    "        svm_grid.fit(X_train_scaled, y_train)\n",
    "        svm_pred = svm_grid.predict(X_test_scaled)\n",
    "        svm_results = self.evaluate_model(y_test, svm_pred, \"SVM\")\n",
    "        models_results.append(svm_results)\n",
    "        \n",
    "        # 3. Random Forest\n",
    "        print(\"Training Random Forest...\")\n",
    "        rf_params = {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [3, 5, 7, None],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "        rf = RandomForestRegressor(random_state=42)\n",
    "        rf_grid = GridSearchCV(rf, rf_params, cv=3, scoring='r2')\n",
    "        rf_grid.fit(X_train, y_train)\n",
    "        rf_pred = rf_grid.predict(X_test)\n",
    "        rf_results = self.evaluate_model(y_test, rf_pred, \"Random Forest\")\n",
    "        models_results.append(rf_results)\n",
    "        \n",
    "        # 4. XGBoost\n",
    "        print(\"Training XGBoost...\")\n",
    "        xgb_params = {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'learning_rate': [0.01, 0.1, 0.2]\n",
    "        }\n",
    "        xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "        xgb_grid = GridSearchCV(xgb_model, xgb_params, cv=3, scoring='r2')\n",
    "        xgb_grid.fit(X_train, y_train)\n",
    "        xgb_pred = xgb_grid.predict(X_test)\n",
    "        xgb_results = self.evaluate_model(y_test, xgb_pred, \"XGBoost\")\n",
    "        models_results.append(xgb_results)\n",
    "        \n",
    "        #"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
