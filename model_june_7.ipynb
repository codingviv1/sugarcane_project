{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "144e92c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, LSTM, Dense, Dropout\n",
    "import keras_tuner as kt \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0cb7ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Evaluation Metrics:\n",
      "                      R2          RMSE           MAE\n",
      "ARIMA         -0.918486  18225.764464  14124.846541\n",
      "Random Forest  0.244827  11434.825969  11321.500000\n",
      "XGBoost       -0.686944  17090.574712  13144.187500\n",
      "Ensemble       0.154249  12101.177073  11994.604123\n",
      "\n",
      "ðŸ“… Year-wise Predictions:\n",
      "    Year  Actual          ARIMA  Random Forest       XGBoost       Ensemble\n",
      "0  2021  362320  364926.721672      352604.39  338252.53125  351927.880974\n",
      "1  2022  336003  361645.971410      348930.39  338223.90625  349600.089220\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# === 1. Dataset ===\n",
    "data = {\n",
    "    'Year': list(range(2008, 2023)),\n",
    "    'Land_used(ha)': [\n",
    "        380543, 391291, 389471, 308104, 338626,\n",
    "        329303, 375216, 376530, 447204, 453470,\n",
    "        442958, 396397, 366426, 362320, 336003\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# === 2. Create lag features ===\n",
    "def create_lag_features(series, window=3):\n",
    "    X, y, years = [], [], []\n",
    "    for i in range(window, len(series)):\n",
    "        X.append(series[i-window:i])\n",
    "        y.append(series[i])\n",
    "        years.append(df['Year'][i])\n",
    "    return np.array(X), np.array(y), years\n",
    "\n",
    "land_used_series = df['Land_used(ha)'].values\n",
    "X_lag, y_lag, target_years = create_lag_features(land_used_series, window=3)\n",
    "X_train, y_train = X_lag[:10], y_lag[:10]\n",
    "X_test, y_test = X_lag[10:], y_lag[10:]\n",
    "test_years = target_years[10:]\n",
    "\n",
    "# === 3. Random Forest ===\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_preds = rf_model.predict(X_test)\n",
    "\n",
    "# === 4. XGBoost ===\n",
    "xgb_model = XGBRegressor(n_estimators=100, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_preds = xgb_model.predict(X_test)\n",
    "\n",
    "# === 5. ARIMA ===\n",
    "arima_preds = []\n",
    "full_series = list(land_used_series[:13])  # up to 2020\n",
    "\n",
    "for i in range(2):  # predict 2021 & 2022\n",
    "    model = ARIMA(full_series, order=(2, 1, 0))\n",
    "    model_fit = model.fit()\n",
    "    forecast = model_fit.forecast()[0]\n",
    "    arima_preds.append(forecast)\n",
    "    full_series.append(df['Land_used(ha)'][13 + i])\n",
    "\n",
    "# === 6. Ensemble ===\n",
    "ensemble_preds = (rf_preds + xgb_preds + arima_preds) / 3\n",
    "\n",
    "# === 7. Evaluation ===\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    return {\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "eval_results = {\n",
    "    \"ARIMA\": evaluate_model(y_test, arima_preds),\n",
    "    \"Random Forest\": evaluate_model(y_test, rf_preds),\n",
    "    \"XGBoost\": evaluate_model(y_test, xgb_preds),\n",
    "    \"Ensemble\": evaluate_model(y_test, ensemble_preds)\n",
    "}\n",
    "eval_df = pd.DataFrame(eval_results).T\n",
    "print(\"ðŸ“Š Evaluation Metrics:\\n\", eval_df)\n",
    "\n",
    "# === 8. Prediction Table ===\n",
    "predictions_table = pd.DataFrame({\n",
    "    \"Year\": test_years,\n",
    "    \"Actual\": y_test,\n",
    "    \"ARIMA\": arima_preds,\n",
    "    \"Random Forest\": rf_preds,\n",
    "    \"XGBoost\": xgb_preds,\n",
    "    \"Ensemble\": ensemble_preds\n",
    "})\n",
    "print(\"\\nðŸ“… Year-wise Predictions:\\n\", predictions_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04ef8a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Evaluation Table:\n",
      "                      R2          RMSE           MAE\n",
      "ARIMA         -0.062817  47989.542793  42100.136708\n",
      "Random Forest  0.098321  44202.159327  36002.921667\n",
      "XGBoost        0.323965  38273.836749  22877.481771\n",
      "Ensemble       0.311988  38611.377271  32357.659175\n",
      "\n",
      "ðŸ“… Year-wise Prediction Table:\n",
      "     Year  Actual          ARIMA  Random Forest       XGBoost       Ensemble\n",
      "0   2011  308104  389356.285687      353366.65  308104.12500  350275.686896\n",
      "1   2012  338626  389407.042522      344158.71  338223.90625  357263.219591\n",
      "2   2013  329303  389465.251315      340942.37  330823.90625  353743.842522\n",
      "3   2014  375216  389471.475497      377506.06  375472.21875  380816.584749\n",
      "4   2015  376530  389469.808831      404145.11  378998.78125  390871.233360\n",
      "5   2016  447204  389469.257512      413120.11  447028.37500  416539.247504\n",
      "6   2017  453470  389469.250702      400107.38  428215.03125  405930.553984\n",
      "7   2018  442958  389469.277655      354969.97  338252.53125  360897.259635\n",
      "8   2019  396397  389469.282577      339457.25  338252.53125  355726.354609\n",
      "9   2020  366426  389469.281963      341396.28  338223.90625  356363.156071\n",
      "10  2021  362320  389469.281579      376469.04  375472.21875  380470.180110\n",
      "11  2022  336003  389469.281545      404145.11  376249.81250  389954.734682\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# === 1. Data ===\n",
    "import pandas as pd\n",
    "\n",
    "# === 1. Load from Excel ===\n",
    "df = pd.read_excel(\"Australia.xlsx\")\n",
    "\n",
    "# === 2. Use only 'Year' and 'Land_used(ha)' columns ===\n",
    "df = df[['Year', 'Land_used(ha)']].copy()\n",
    "\n",
    "# (Optional) Sort by year just in case\n",
    "df = df.sort_values('Year').reset_index(drop=True)\n",
    "\n",
    "# Proceed with rest of the code unchanged\n",
    "land_used = df['Land_used(ha)'].values\n",
    "years = df['Year'].tolist()\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# === 2. Create initial training data ===\n",
    "def create_lag_features(series, window=3):\n",
    "    X, y = [], []\n",
    "    for i in range(window, len(series)):\n",
    "        X.append(series[i-window:i])\n",
    "        y.append(series[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "land_used = df['Land_used(ha)'].values\n",
    "X_train, y_train = create_lag_features(land_used[:13], window=3)  # up to 2010 â†’ predict till 2020\n",
    "\n",
    "# === 3. Train models ===\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "xgb = XGBRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# === 4. Recursive prediction from 2011 to 2022 ===\n",
    "years = list(df['Year'][3:])  # 2011â€“2022\n",
    "actual = list(df['Land_used(ha)'][3:])\n",
    "\n",
    "rf_preds, xgb_preds, arima_preds = [], [], []\n",
    "series_rf = list(land_used[:3])  # starting with 2008â€“2010\n",
    "series_arima = list(land_used[:3])\n",
    "\n",
    "for _ in range(len(years)):\n",
    "    # Random Forest & XGBoost\n",
    "    input_seq = np.array(series_rf[-3:]).reshape(1, -1)\n",
    "    rf_pred = rf.predict(input_seq)[0]\n",
    "    xgb_pred = xgb.predict(input_seq)[0]\n",
    "    rf_preds.append(rf_pred)\n",
    "    xgb_preds.append(xgb_pred)\n",
    "    series_rf.append(rf_pred)  # update for next iteration\n",
    "\n",
    "    # ARIMA\n",
    "    model = ARIMA(series_arima, order=(2, 1, 0))\n",
    "    model_fit = model.fit()\n",
    "    arima_pred = model_fit.forecast()[0]\n",
    "    arima_preds.append(arima_pred)\n",
    "    series_arima.append(arima_pred)\n",
    "\n",
    "# === 5. Ensemble ===\n",
    "ensemble_preds = (np.array(rf_preds) + np.array(xgb_preds) + np.array(arima_preds)) / 3\n",
    "\n",
    "# === 6. Evaluation ===\n",
    "def evaluate(y_true, y_pred):\n",
    "    return {\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "results = {\n",
    "    \"ARIMA\": evaluate(actual, arima_preds),\n",
    "    \"Random Forest\": evaluate(actual, rf_preds),\n",
    "    \"XGBoost\": evaluate(actual, xgb_preds),\n",
    "    \"Ensemble\": evaluate(actual, ensemble_preds)\n",
    "}\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nðŸ“Š Evaluation Table:\\n\", results_df)\n",
    "\n",
    "# === 7. Final Predictions ===\n",
    "pred_table = pd.DataFrame({\n",
    "    \"Year\": years,\n",
    "    \"Actual\": actual,\n",
    "    \"ARIMA\": arima_preds,\n",
    "    \"Random Forest\": rf_preds,\n",
    "    \"XGBoost\": xgb_preds,\n",
    "    \"Ensemble\": ensemble_preds\n",
    "})\n",
    "print(\"\\nðŸ“… Year-wise Prediction Table:\\n\", pred_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba017be",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '380,543\\xa0'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     34\u001b[39m rf = RandomForestRegressor(n_estimators=\u001b[32m100\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m     35\u001b[39m xgb = XGBRegressor(n_estimators=\u001b[32m100\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[43mrf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m xgb.fit(X_train, y_train)\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# === 4. Train LSTM and GRU ===\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:360\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m360\u001b[39m X, y = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[38;5;66;03m# _compute_missing_values_in_feature_mask checks if X has missing values and\u001b[39;00m\n\u001b[32m    370\u001b[39m \u001b[38;5;66;03m# will raise an error if the underlying tree base estimator can't handle missing\u001b[39;00m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# values. Only the criterion is required to determine if the tree supports\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[38;5;66;03m# missing values.\u001b[39;00m\n\u001b[32m    373\u001b[39m estimator = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m.estimator)(criterion=\u001b[38;5;28mself\u001b[39m.criterion)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2961\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2959\u001b[39m         y = check_array(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, **check_y_params)\n\u001b[32m   2960\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2961\u001b[39m         X, y = \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2962\u001b[39m     out = X, y\n\u001b[32m   2964\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1370\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1364\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1365\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires y to be passed, but the target y is None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1366\u001b[39m     )\n\u001b[32m   1368\u001b[39m ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[32m-> \u001b[39m\u001b[32m1370\u001b[39m X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1385\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1387\u001b[39m y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n\u001b[32m   1389\u001b[39m check_consistent_length(X, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1055\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1053\u001b[39m         array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1054\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1055\u001b[39m         array = \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1056\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1057\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1058\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.format(array)\n\u001b[32m   1059\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomplex_warning\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:839\u001b[39m, in \u001b[36m_asarray_with_order\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    837\u001b[39m     array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    838\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m839\u001b[39m     array = \u001b[43mnumpy\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    842\u001b[39m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[32m    843\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m xp.asarray(array)\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: '380,543\\xa0'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# === 1. Load and Prepare Data ===\n",
    "df = pd.read_excel(\"Australia.xlsx\")\n",
    "df = df[['Year', 'Land_used(ha)']].sort_values('Year').reset_index(drop=True)\n",
    "\n",
    "land_used = df['Land_used(ha)'].values\n",
    "years = df['Year'].tolist()\n",
    "\n",
    "# === 2. Create Lag Features ===                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
    "def create_lag_features(series, window=3):\n",
    "    X, y = [], []\n",
    "    for i in range(window, len(series)):\n",
    "        X.append(series[i-window:i])\n",
    "        y.append(series[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# 2008â€“2010 â†’ predict up to 2020 (index 0 to 12), 2011â€“2022 are predictions\n",
    "X_train, y_train = create_lag_features(land_used[:13], window=3)\n",
    "actual = list(land_used[3:])  # Actual values for 2011â€“2022\n",
    "\n",
    "# === 3. Train RF and XGB ===\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "xgb = XGBRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# === 4. Train LSTM and GRU ===\n",
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(land_used[:13].reshape(-1, 1)).flatten()\n",
    "X_seq, y_seq = create_lag_features(scaled, 3)\n",
    "X_seq = X_seq.reshape((X_seq.shape[0], 3, 1))\n",
    "\n",
    "# LSTM\n",
    "lstm = Sequential([LSTM(50, activation='relu', input_shape=(3,1)), Dense(1)])\n",
    "lstm.compile(optimizer=Adam(0.01), loss='mse')\n",
    "lstm.fit(X_seq, y_seq, epochs=200, verbose=0)\n",
    "\n",
    "# GRU\n",
    "gru = Sequential([GRU(50, activation='relu', input_shape=(3,1)), Dense(1)])\n",
    "gru.compile(optimizer=Adam(0.01), loss='mse')\n",
    "gru.fit(X_seq, y_seq, epochs=200, verbose=0)\n",
    "\n",
    "# === 5. Recursive Prediction (2011â€“2022) ===\n",
    "series_rf = list(land_used[:3])\n",
    "series_arima = list(land_used[:3])\n",
    "series_dl = list(scaled[:3])\n",
    "\n",
    "rf_preds, xgb_preds, arima_preds, lstm_preds, gru_preds = [], [], [], [], []\n",
    "\n",
    "for _ in range(len(actual)):\n",
    "    # RF & XGB\n",
    "    input_seq = np.array(series_rf[-3:]).reshape(1, -1)\n",
    "    rf_pred = rf.predict(input_seq)[0]\n",
    "    xgb_pred = xgb.predict(input_seq)[0]\n",
    "    rf_preds.append(rf_pred)\n",
    "    xgb_preds.append(xgb_pred)\n",
    "    series_rf.append(rf_pred)\n",
    "\n",
    "    # ARIMA\n",
    "    model = ARIMA(series_arima, order=(2, 1, 0))\n",
    "    model_fit = model.fit()\n",
    "    arima_pred = model_fit.forecast()[0]\n",
    "    arima_preds.append(arima_pred)\n",
    "    series_arima.append(arima_pred)\n",
    "\n",
    "    # LSTM\n",
    "    input_lstm = np.array(series_dl[-3:]).reshape(1, 3, 1)\n",
    "    pred_lstm_scaled = lstm.predict(input_lstm, verbose=0)[0][0]\n",
    "    pred_lstm = scaler.inverse_transform([[pred_lstm_scaled]])[0][0]\n",
    "    lstm_preds.append(pred_lstm)\n",
    "    series_dl.append(scaler.transform([[pred_lstm]])[0][0])\n",
    "\n",
    "    # GRU\n",
    "    input_gru = np.array(series_dl[-3:]).reshape(1, 3, 1)\n",
    "    pred_gru_scaled = gru.predict(input_gru, verbose=0)[0][0]\n",
    "    pred_gru = scaler.inverse_transform([[pred_gru_scaled]])[0][0]\n",
    "    gru_preds.append(pred_gru)\n",
    "    series_dl.append(scaler.transform([[pred_gru]])[0][0])\n",
    "\n",
    "# === 6. Ensemble ===\n",
    "ensemble_preds = (np.array(rf_preds) + np.array(xgb_preds) + np.array(arima_preds) +\n",
    "                  np.array(lstm_preds) + np.array(gru_preds)) / 5\n",
    "\n",
    "# === 7. Evaluation ===\n",
    "def evaluate(y_true, y_pred):\n",
    "    return {\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "results = {\n",
    "    \"ARIMA\": evaluate(actual, arima_preds),\n",
    "    \"Random Forest\": evaluate(actual, rf_preds),\n",
    "    \"XGBoost\": evaluate(actual, xgb_preds),\n",
    "    \"LSTM\": evaluate(actual, lstm_preds),\n",
    "    \"GRU\": evaluate(actual, gru_preds),\n",
    "    \"Ensemble\": evaluate(actual, ensemble_preds)\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nðŸ“Š Evaluation Table:\\n\", results_df)\n",
    "\n",
    "# === 8. Final Prediction Table ===\n",
    "pred_table = pd.DataFrame({\n",
    "    \"Year\": df['Year'][3:],\n",
    "    \"Actual\": actual,\n",
    "    \"ARIMA\": arima_preds,\n",
    "    \"Random Forest\": rf_preds,\n",
    "    \"XGBoost\": xgb_preds,\n",
    "    \"LSTM\": lstm_preds,\n",
    "    \"GRU\": gru_preds,\n",
    "    \"Ensemble\": ensemble_preds\n",
    "})\n",
    "print(\"\\nðŸ“… Year-wise Prediction Table:\\n\", pred_table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
